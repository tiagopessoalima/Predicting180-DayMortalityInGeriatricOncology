{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d60c4dda",
   "metadata": {},
   "source": [
    "# LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "492d907d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom imports\n",
    "from constants import RANDOM_STATE\n",
    "from functions import geometric_mean_score, roughly_balanced_bagging\n",
    "\n",
    "# imbalanced-learn imports\n",
    "from imblearn import FunctionSampler\n",
    "from imblearn.ensemble import BalancedBaggingClassifier, BalancedRandomForestClassifier\n",
    "from imblearn.over_sampling import ADASYN, BorderlineSMOTE, RandomOverSampler, SMOTE, SVMSMOTE \n",
    "from imblearn.under_sampling import ClusterCentroids, NearMiss, RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# joblib-related imports\n",
    "from joblib import dump\n",
    "\n",
    "# scikit-learn imports\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, KNNImputer, SimpleImputer \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MaxAbsScaler, MinMaxScaler, QuantileTransformer, RobustScaler, StandardScaler \n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# scikit-optimize imports\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "# standard Python imports\n",
    "import warnings\n",
    "import unidecode\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# additional settings\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236d449f",
   "metadata": {},
   "source": [
    "# READ FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d203e563",
   "metadata": {},
   "source": [
    "Read the training data from the CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb4a678d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('../dataset/X_train.csv', index_col=0)\n",
    "y_train = pd.read_csv('../dataset/y_train.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4518cfe",
   "metadata": {},
   "source": [
    "# MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a6fde3",
   "metadata": {},
   "source": [
    "A pipeline for data normalization and balancing is used to prepare imbalanced datasets, improving model performance on minority classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23704ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(model, normalizer=True, imputation=True, balancer=True):\n",
    "\n",
    "    steps = []\n",
    "    \n",
    "    if normalizer:\n",
    "        steps.append(('normalization', None))\n",
    "        \n",
    "    if imputation:\n",
    "        steps.append(('imputation', None))\n",
    "                \n",
    "    if balancer:\n",
    "        steps.append(('balance', None))\n",
    "       \n",
    "    steps.append((model.__class__.__name__.lower(), model))    \n",
    "   \n",
    "    return Pipeline(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75944d8e",
   "metadata": {},
   "source": [
    "- These are the normalization techniques evaluated in this pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f1e26a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization = [\n",
    "    MaxAbsScaler(),\n",
    "    MinMaxScaler(), \n",
    "    QuantileTransformer(output_distribution='normal'),\n",
    "    RobustScaler(), \n",
    "    StandardScaler()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27e247f",
   "metadata": {},
   "source": [
    "- These are the imputation techniques evaluated in this pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "261e2c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation = [\n",
    "    SimpleImputer(strategy='mean'),  # Fill with mean\n",
    "    SimpleImputer(strategy='median'),  # Fill with median\n",
    "    IterativeImputer(max_iter=10, random_state=RANDOM_STATE),  # Iterative imputation\n",
    "    KNNImputer(n_neighbors=3, weights='uniform'),  # K-nearest neighbors-based imputation\n",
    "    KNNImputer(n_neighbors=5, weights='uniform'),  # K-nearest neighbors-based imputation\n",
    "    KNNImputer(n_neighbors=7, weights='uniform'),  # K-nearest neighbors-based imputation\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a051c0",
   "metadata": {},
   "source": [
    "- These are the balancing techniques evaluated in this pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86b41d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "balancing = [\n",
    "    ADASYN(random_state=RANDOM_STATE), \n",
    "    BorderlineSMOTE(random_state=RANDOM_STATE),\n",
    "    ClusterCentroids(random_state=RANDOM_STATE),\n",
    "    NearMiss(),\n",
    "    RandomOverSampler(random_state=RANDOM_STATE),\n",
    "    RandomUnderSampler(random_state=RANDOM_STATE),\n",
    "    SMOTE(random_state=RANDOM_STATE), \n",
    "    SMOTEENN(random_state=RANDOM_STATE),\n",
    "    SMOTETomek(random_state=RANDOM_STATE),\n",
    "    SVMSMOTE(random_state=RANDOM_STATE)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c6a020",
   "metadata": {},
   "source": [
    "We will examine ensemble techniques and some classification models in a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "040877cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define common settings\n",
    "common_settings = {\n",
    "    'normalization': Categorical(normalization),\n",
    "    'imputation': Categorical(imputation),\n",
    "    'balance': Categorical(balancing),\n",
    "    'balance__sampling_strategy': Real(0.5, 1.0),\n",
    "}\n",
    "\n",
    "# Define specific settings for each model\n",
    "models = {      \n",
    "    'LR': {\n",
    "        'model': create_pipeline(LogisticRegression(random_state=RANDOM_STATE)),\n",
    "        'space': {\n",
    "            'logisticregression__C': Real(1e-3, 1e+3),\n",
    "            'logisticregression__max_iter': Integer(1e+2, 1e+4),\n",
    "            'logisticregression__solver': Categorical(['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']),\n",
    "            'logisticregression__fit_intercept': Categorical([True, False]),\n",
    "            'logisticregression__class_weight': Categorical(['balanced', None]),\n",
    "            'logisticregression__l1_ratio': Real(0, 1),\n",
    "            **common_settings\n",
    "        },\n",
    "    },\n",
    "    'MLP': {\n",
    "        'model': create_pipeline(MLPClassifier(random_state=RANDOM_STATE)),\n",
    "        'space': {\n",
    "            'mlpclassifier__hidden_layer_sizes': Integer(2, 20),\n",
    "            'mlpclassifier__activation': Categorical(['logistic', 'tanh', 'relu']),\n",
    "            'mlpclassifier__max_iter': Integer(1e3, 1e5),\n",
    "            'mlpclassifier__alpha': Real(1e-3, 1e0),\n",
    "            'mlpclassifier__learning_rate': Categorical(['constant', 'adaptive']),\n",
    "            'mlpclassifier__learning_rate_init': Real(1e-4, 1e-1),\n",
    "            'mlpclassifier__momentum': Real(0.1, 0.9),\n",
    "            'mlpclassifier__early_stopping': Categorical([True, False]),\n",
    "            'mlpclassifier__validation_fraction': Real(0.25, 0.50),\n",
    "            'mlpclassifier__beta_1': Real(0.8, 0.99),\n",
    "            'mlpclassifier__beta_2': Real(0.8, 0.99),\n",
    "            'mlpclassifier__epsilon': Real(1e-8, 1e-6),\n",
    "            **common_settings\n",
    "        },\n",
    "    },\n",
    "    'SVM': {\n",
    "        'model': create_pipeline(SVC(probability=True, random_state=RANDOM_STATE)),\n",
    "        'space': {\n",
    "            'svc__C': Real(1e-3, 1e+3),\n",
    "            'svc__gamma': Real(1e-4, 1e-1),\n",
    "            'svc__kernel': Categorical(['linear', 'rbf', 'poly', 'sigmoid']),\n",
    "            'svc__degree': Integer(1, 5),\n",
    "            'svc__coef0': Real(0, 1),\n",
    "            'svc__shrinking': Categorical([True, False]),\n",
    "            'svc__class_weight': Categorical([None, 'balanced']),\n",
    "            'svc__max_iter': Integer(1e3, 1e5),\n",
    "            'svc__tol': Real(1e-6, 1e-2),\n",
    "            **common_settings\n",
    "        },\n",
    "    },\n",
    "    'RF': {\n",
    "        'model': create_pipeline(RandomForestClassifier(random_state=RANDOM_STATE)),\n",
    "        'space': {\n",
    "            'randomforestclassifier__n_estimators': Integer(1e1, 1e3),\n",
    "            'randomforestclassifier__max_depth': Integer(1, 20),\n",
    "            'randomforestclassifier__criterion': Categorical(['gini', 'entropy']),\n",
    "            'randomforestclassifier__min_samples_split': Integer(2, 10),\n",
    "            'randomforestclassifier__min_samples_leaf': Integer(1, 10),\n",
    "            'randomforestclassifier__max_features': Categorical(['sqrt', 'log2']),\n",
    "            'randomforestclassifier__max_samples': Real(0.1, 1.0),\n",
    "            'randomforestclassifier__class_weight': Categorical(['balanced', 'balanced_subsample']),\n",
    "            **common_settings\n",
    "        },\n",
    "    },\n",
    "    'GB': {\n",
    "        'model': create_pipeline(GradientBoostingClassifier(random_state=RANDOM_STATE)),\n",
    "        'space': {\n",
    "            'gradientboostingclassifier__n_estimators': Integer(1e1, 1e3),\n",
    "            'gradientboostingclassifier__learning_rate': Real(0.01, 1.0),\n",
    "            'gradientboostingclassifier__max_depth': Integer(1, 10),\n",
    "            'gradientboostingclassifier__min_samples_split': Real(0.01, 1.0),\n",
    "            'gradientboostingclassifier__min_samples_leaf': Real(0.01, 0.5),\n",
    "            'gradientboostingclassifier__max_features': Categorical(['auto', 'sqrt', 'log2']),\n",
    "            **common_settings\n",
    "        },\n",
    "    },\n",
    "    'EBB': {\n",
    "        'model': create_pipeline(BalancedBaggingClassifier(\n",
    "            sampler=RandomUnderSampler(random_state=RANDOM_STATE), \n",
    "            random_state=RANDOM_STATE), balancer=False),\n",
    "        'space': {\n",
    "            'balancedbaggingclassifier__n_estimators': Integer(1e1, 1e3),\n",
    "            'balancedbaggingclassifier__max_samples': Real(0.1, 1.0),\n",
    "            'balancedbaggingclassifier__max_features': Real(0.4, 1.0),\n",
    "            'balancedbaggingclassifier__sampling_strategy': Real(0.5, 1.0),\n",
    "            'normalization': Categorical(normalization),\n",
    "            'imputation': Categorical(imputation),\n",
    "        },\n",
    "    },\n",
    "    'OB': {\n",
    "        'model': create_pipeline(BalancedBaggingClassifier(\n",
    "            sampler=RandomOverSampler(random_state=RANDOM_STATE), \n",
    "            random_state=RANDOM_STATE), balancer=False),\n",
    "        'space': {\n",
    "            'balancedbaggingclassifier__n_estimators': Integer(1e1, 1e3),\n",
    "            'balancedbaggingclassifier__max_samples': Real(0.1, 1.0),\n",
    "            'balancedbaggingclassifier__max_features': Real(0.4, 1.0),\n",
    "            'balancedbaggingclassifier__sampling_strategy': Real(0.5, 1.0),\n",
    "            'normalization': Categorical(normalization),\n",
    "            'imputation': Categorical(imputation),    \n",
    "        },\n",
    "    },\n",
    "    'SB': {\n",
    "        'model': create_pipeline(BalancedBaggingClassifier(\n",
    "            sampler=SMOTE(random_state=RANDOM_STATE), \n",
    "            random_state=RANDOM_STATE), balancer=False),\n",
    "        'space': {\n",
    "            'balancedbaggingclassifier__n_estimators': Integer(1e1, 1e3),\n",
    "            'balancedbaggingclassifier__max_samples': Real(0.1, 1.0),\n",
    "            'balancedbaggingclassifier__max_features': Real(0.4, 1.0),\n",
    "            'balancedbaggingclassifier__sampling_strategy': Real(0.5, 1.0),\n",
    "            'normalization': Categorical(normalization),\n",
    "            'imputation': Categorical(imputation),   \n",
    "        },\n",
    "    },\n",
    "    'RRB': {\n",
    "        'model': create_pipeline(BalancedBaggingClassifier(\n",
    "            sampler=FunctionSampler(func=roughly_balanced_bagging, kw_args={\"replace\": True}),\n",
    "            random_state=RANDOM_STATE), balancer=False),\n",
    "        'space': {\n",
    "            'balancedbaggingclassifier__n_estimators': Integer(1e1, 1e3),\n",
    "            'balancedbaggingclassifier__max_samples': Real(0.1, 1.0),\n",
    "            'balancedbaggingclassifier__max_features': Real(0.4, 1.0),\n",
    "            'normalization': Categorical(normalization),\n",
    "            'imputation': Categorical(imputation),\n",
    "        },\n",
    "    },\n",
    "    'BRF': {\n",
    "        'model': create_pipeline(BalancedRandomForestClassifier(\n",
    "            random_state=RANDOM_STATE), balancer=False),\n",
    "        'space': {\n",
    "            'balancedrandomforestclassifier__n_estimators': Integer(1e1, 1e3),\n",
    "            'balancedrandomforestclassifier__criterion': Categorical(['gini', 'entropy']),\n",
    "            'balancedrandomforestclassifier__max_depth': Integer(2, 10),\n",
    "            'balancedrandomforestclassifier__min_samples_split': Integer(2, 10),\n",
    "            'balancedrandomforestclassifier__min_samples_leaf': Integer(1, 10),\n",
    "            'balancedrandomforestclassifier__max_samples': Real(0.1, 1.0),\n",
    "            'balancedrandomforestclassifier__max_features': Categorical(['sqrt', 'log2']),\n",
    "            'balancedrandomforestclassifier__class_weight': Categorical(['balanced', 'balanced_subsample']),\n",
    "            'balancedrandomforestclassifier__sampling_strategy': Real(0.5, 1.0),\n",
    "            'normalization': Categorical(normalization),\n",
    "            'imputation': Categorical(imputation),  \n",
    "        },\n",
    "    },  \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2124a2",
   "metadata": {},
   "source": [
    "We create a BayesSearchCV object tailored to optimize the hyperparameters of the respective model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8785149f",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = {\n",
    "    model_name: BayesSearchCV(\n",
    "        models[model_name]['model'],  # Model to be optimized\n",
    "        models[model_name]['space'],  # Hyperparameter search space\n",
    "        n_iter=20,  # Number of search iterations\n",
    "        cv=RepeatedStratifiedKFold(random_state=RANDOM_STATE),  # Cross-validation strategy\n",
    "        random_state=RANDOM_STATE,  # Random state for reproducibility\n",
    "        scoring=make_scorer(geometric_mean_score)  # Custom metric for optimization\n",
    "    )  # Create instances of BayesSearchCV for each model\n",
    "    for model_name in models  # Iterate through model names in the 'models' dictionary\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4736dde9",
   "metadata": {},
   "source": [
    "The code below optimizes machine learning models, records the best score during cross-validation, and saves the trained models to files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30c82d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- LR:  0.5830\n",
      "- MLP:  0.5853\n",
      "- SVM:  0.5985\n",
      "- RF:  0.5831\n",
      "- GB:  0.5800\n",
      "- EBB:  0.5943\n",
      "- OB:  0.4970\n",
      "- SB:  0.5403\n",
      "- RRB:  0.5923\n",
      "- BRF:  0.5783\n"
     ]
    }
   ],
   "source": [
    "for model_name, model_opt in opt.items():\n",
    "    # Print the model name followed by a colon\n",
    "    print(f'- {model_name}: ', end=' ')\n",
    "    \n",
    "    # Fit the model\n",
    "    model_opt.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best score achieved by the model during cross-validation\n",
    "    best_score = model_opt.best_score_\n",
    "\n",
    "    # Print the best score\n",
    "    print(f'{best_score:.4f}')\n",
    "\n",
    "    # Generate the filename for saving the trained model\n",
    "    model_filename = f'../models/{model_name}.joblib'\n",
    "\n",
    "    # Save the best estimator to a file\n",
    "    dump(model_opt.best_estimator_, model_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
